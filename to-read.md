# Sensor Fusion

## 1. List

## 2. Paper


- [Performance Limits of Track-to-Track Fusion vs. Centralized Estimation: Theory and Application](http://fusion.isif.org/proceedings/fusion01CD/fusion/searchengine/pdf/TuB14.pdf?)

- [Track-to-track Fusion for Multi-target Tracking Using Asynchronous and Delayed Data](http://publications.lib.chalmers.se/records/fulltext/250403/250403.pdf): 2017, 69p

* [A Survey of ADAS Technologies for the Future Perspective of Sensor Fusion](https://link.springer.com/chapter/10.1007/978-3-319-45246-3_13)
* [VANETs Meet Autonomous Vehicles: A Multimodal 3D Environment Learning Approach](https://arxiv.org/abs/1705.08624)

* [Multi-Modal Obstacle Detection in Unstructured Environments with Conditional Random Fields](https://arxiv.org/abs/1706.02908): 2017.06
* Unstructured Environments: 농장
* lidar + camera sensing using a conditional random field
* [Fusing LIDAR and images for pedestrian detection using convolutional neural networks](http://ieeexplore.ieee.org/abstract/document/7487370/): 2016.04
* Multiview random forest of local experts combining rgb and lidar data for pedestrian detection [\[Gonzalez, IV '15\]](https://scholar.google.de/scholar?q=Multiview Random Forest of Local Experts Combining RGB and LIDAR data for Pedestrian Detection)

* Pedestrian Detection Combining RGB and Dense LIDAR Data [\[Premebida, IROS '14\]](https://people.eecs.berkeley.edu/~carreira/papers/iros2014.pdf) [\[Project\]](http://home.isr.uc.pt/~cpremebida/IROS14/LaserVisionFusion.html) [\[Code\]](http://home.isr.uc.pt/~cpremebida/IROS14/Codes_CP_IROS2014.zip)
* [Radar/Lidar sensor fusion for car-following on highways](http://ieeexplore.ieee.org/abstract/document/6144918/): 2011


- Shruti Gangadhar, SENSOR FUSION FRAMEWORK AND SIMULATION ON A TURTLEBOT ROBOTIC VEHICLE, 2017, [석사학위](https://webpages.uncc.edu/~jmconrad/GradStudents/Thesis_Gangadhar.pdf)


- A comparative study of data fusion for RGB-D based visual recognition : A study of data fusion methods for RGB-D visual recognition can be found in Sanchez-Riera et al. [2016].


- C. Lundquist, “Sensor fusion for automotive applications,” Ph.D. dissertation, Linkoping University, Link ¨ oping, 2011. ¨

- N.-E. E. Faouzi, H. Leung, and A. Kurian, “Data fusion in intelligent transportation systems: Progress and challenges : A survey,” Information Fusion, vol. 12, no. 1, pp. 4 – 10, 2011.



- ~~[Object Detection and Classification by Decision-Level Fusion for Intelligent Vehicle Systems](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5298778/)~~: 2017, KITTI, 21p

- ~~[FUSION OF LIDAR 3D POINTS CLOUD WITH 2D DIGITAL CAMERA IMAGE](http://www.secs.oakland.edu/~li4/research/student/JuanLi2015.pdf)~~: 2015, 석사학위, 90p, 라이다+카메라 -> RGB-D 정보 획득하기, transformatio 논문



- ~~[A Survey of ADAS Technologies for the Future Perspective of Sensor Fusion](https://link.springer.com/chapter/10.1007/978-3-319-45246-3_13)~~: 2016, 일반적 설명

- FusionNet: A deep fully residual convolutional neural network for image segmentation in connectomics: 2016

- FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-Based CNN Architecture: 2016, Depth Information, Semantic Segmentation, Depth Image, CNN, RGB





- ~~Multi-Sensor Fusion of Occupancy Grids based on Integer Arithmetic~~: Fusion 프레임워크 제안, 기본 익힌후 살펴 보기

- Fusing LIDAR and Images for Pedestrian Detection using Convolutional Neural Networks, Schlosser

- Motion-based Detection and Tracking in 3D LiDAR Scans, Dewan


- ~~[Multiple Sensor Fusion and Classification for Moving Object Detection and Tracking](http://ieeexplore.ieee.org/document/7283636/)~~: 2015, 관련연구의 퓨전 레벨 부분만 참고 함

- [Object Perception for Intelligent Vehicle Applications:A Multi-Sensor Fusion Approach](https://hal.inria.fr/hal-01019527/document): 2014

- ~~[Sensor Modality Fusion with CNNs for UGV Autonomous Driving in Indoor Environments](http://cims.nyu.edu/~achoroma/NonFlash/Papers/SMF_CNN.pdf)~~: 2017, 모형 자동차, 카메라+라이다 연동, DNN 제안

- [Acoustic/Lidar Sensor Fusion for Car Tracking in City Traffic Scenarios](http://www.drgoehring.de/bib/tadjine15fastzero/tadjine15fastzero.pdf)

- [Trends in Sensor and Data Fusion](http://www.ifp.uni-stuttgart.de/publications/phowo05/300roth.pdf): 2005

## 3. Article (Post, blog, etc.)

- ~~[Expert Advice: Sensor Fusion for Highly Automated Driving](http://gpsworld.com/expert-advice-sensor-fusion-for-highly-automated-driving/)~~: GNSS관련, 구체적 내용 없음

- [Particle Filter Implementation](https://medium.com/@andrew.d.wilkie/self-driving-car-engineer-diary-9-898f075e888c): 하단

- 추천 : [Tracking pedestrians for self driving cars](https://medium.com/towards-data-science/tracking-pedestrians-for-self-driving-cars-ccf588acd170)
- 추천 : [Tracking a self-driving car with high precision](https://medium.com/@priya.dwivedi/latest)

- [Object tracking with LIDAR, Radar, sensor fusion and Extended Kalman Filter](http://www.coldvision.io/2017/04/15/object-tracking-with-lidar-radar-sensor-fusion-and-extended-kalman-filter/): post

- Sensor Fusion Algorithms For Autonomous Driving
- [Part 1 — The Kalman filter and Extended Kalman Filter](https://medium.com/@wilburdes/sensor-fusion-algorithms-for-autonomous-driving-part-1-the-kalman-filter-and-extended-kalman-a4eab8a833dd)

- [Sensor Fusion with Kalman Filter (1/2)](https://winfriedauner.de/projects/extended_kalman/)

- [Sensor Fusion with Kalman Filter (2/2)](https://winfriedauner.de/projects/unscented)

- [Sensor Fusion](http://www.towardsautonomy.com/sensor_fusion)

- [Udacity carnd2 Sensor Fusion, Extended Karman Filter (English)](https://hk.saowen.com/a/cfd402f9504a2c6390b7ca1e4e91d271de65281f5f4d405ae06b94484463e6ae)



## 3. Tutorial (Series, )



## 4. Youtube

- [Vehicle Detection using LiDAR and Camera sensor Fusion](https://www.youtube.com/watch?v=V3cN5LrPr4M)

- [Why You Should Use The Kalman Filter Tutorial - Pokemon Example](https://www.youtube.com/watch?v=bm3cwEP2nUo)

## 6. Material (Pdf, ppt)

- ~~[Sensor Fusion and Calibration of Velodyne LiDAR and RGB Camera ](https://www.it4i.cz/wp-content/uploads/2014/11/RP7_Velas.pdf)~~: ppt

- [Sensor Fusion for Automotive Applications](http://users.isy.liu.se/en/rt/lundquist/Publications/Lundquist2011.pdf): 2011, 331p

## 7. Implementation (Project)

- [An extended Kalman Filter implementation in Python for fusing lidar and radar sensor measurements](https://github.com/mithi/Fusion-EKF-Python): mithi, python
- [Cpp버젼](https://github.com/mithi/fusion-ekf), [CPP버젼v2](https://github.com/mithi/fusion-ekf/tree/master/A-UPDATED-FUSIONEKF)
- [Object-Tracking-and-State-Prediction-with-Unscented-and-Extended-Kalman-Filters](https://github.com/srnand/Object-Tracking-and-State-Prediction-with-Unscented-and-Extended-Kalman-Filters) : 변형

- [Extended Kalman Filter Project Starter Code](https://github.com/udacity/CarND-Extended-Kalman-Filter-Project): Udacity





## 8. Research Group / Conference

[Data fusion development with ROS | BASELABS](https://www.baselabs.de/data-fusion-development-with-ros/): 필독, 샘플파일 제공








